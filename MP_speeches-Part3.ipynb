{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\"><li><span><a href=\"#Part-3:-Train-bigram-and-trigram-models-and-use-them-on-all-speeches\" data-toc-modified-id=\"Part-3:-Train-bigram-and-trigram-models-and-use-them-on-all-speeches-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Part 3: Train bigram and trigram models and use them on all speeches</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#We-use-SpaCy-to-tokenize-and-POS-tag-each-speech\" data-toc-modified-id=\"We-use-SpaCy-to-tokenize-and-POS-tag-each-speech-1.0.1\"><span class=\"toc-item-num\">1.0.1&nbsp;&nbsp;</span>We use SpaCy to tokenize and POS tag each speech</a></span></li><li><span><a href=\"#Load-all-the-speeches-and-metadata-into-a-pandas-dataframe-and-save-into-an-hdf-file\" data-toc-modified-id=\"Load-all-the-speeches-and-metadata-into-a-pandas-dataframe-and-save-into-an-hdf-file-1.0.2\"><span class=\"toc-item-num\">1.0.2&nbsp;&nbsp;</span>Load all the speeches and metadata into a pandas dataframe and save into an hdf file</a></span></li><li><span><a href=\"#Save-speeches-alone-to-a-text-file-to-speed-up-processing\" data-toc-modified-id=\"Save-speeches-alone-to-a-text-file-to-speed-up-processing-1.0.3\"><span class=\"toc-item-num\">1.0.3&nbsp;&nbsp;</span>Save speeches alone to a text file to speed up processing</a></span></li><li><span><a href=\"#Create-a-bunch-of-helper-functions-to-help-us-read-speeches-from-the-file,-remove-punctuation-and-whitespace-and-lemmatize-words\" data-toc-modified-id=\"Create-a-bunch-of-helper-functions-to-help-us-read-speeches-from-the-file,-remove-punctuation-and-whitespace-and-lemmatize-words-1.0.4\"><span class=\"toc-item-num\">1.0.4&nbsp;&nbsp;</span>Create a bunch of helper functions to help us read speeches from the file, remove punctuation and whitespace and lemmatize words</a></span></li><li><span><a href=\"#Lemmatize-all-words-in-speeches-and-store-them-in-text-file-to-save-memory\" data-toc-modified-id=\"Lemmatize-all-words-in-speeches-and-store-them-in-text-file-to-save-memory-1.0.5\"><span class=\"toc-item-num\">1.0.5&nbsp;&nbsp;</span>Lemmatize all words in speeches and store them in text file to save memory</a></span></li><li><span><a href=\"#Learn-bigrams-in-speeches-and-save-model-to-disk\" data-toc-modified-id=\"Learn-bigrams-in-speeches-and-save-model-to-disk-1.0.6\"><span class=\"toc-item-num\">1.0.6&nbsp;&nbsp;</span>Learn bigrams in speeches and save model to disk</a></span></li><li><span><a href=\"#Identify-bigrams-in-the-speeches-and-save-in-txt-file\" data-toc-modified-id=\"Identify-bigrams-in-the-speeches-and-save-in-txt-file-1.0.7\"><span class=\"toc-item-num\">1.0.7&nbsp;&nbsp;</span>Identify bigrams in the speeches and save in txt file</a></span></li><li><span><a href=\"#Learn-trigrams-in-speeches-and-save-model-to-disk\" data-toc-modified-id=\"Learn-trigrams-in-speeches-and-save-model-to-disk-1.0.8\"><span class=\"toc-item-num\">1.0.8&nbsp;&nbsp;</span>Learn trigrams in speeches and save model to disk</a></span></li><li><span><a href=\"#Identify-trigrams-in-the-speeches-and-save-in-txt-file\" data-toc-modified-id=\"Identify-trigrams-in-the-speeches-and-save-in-txt-file-1.0.9\"><span class=\"toc-item-num\">1.0.9&nbsp;&nbsp;</span>Identify trigrams in the speeches and save in txt file</a></span></li><li><span><a href=\"#Now-process-all-speeches-from-plain-text-to-unigram-(lemmatized),-bigram-and-finally-trigram-representation\" data-toc-modified-id=\"Now-process-all-speeches-from-plain-text-to-unigram-(lemmatized),-bigram-and-finally-trigram-representation-1.0.10\"><span class=\"toc-item-num\">1.0.10&nbsp;&nbsp;</span>Now process all speeches from plain text to unigram (lemmatized), bigram and finally trigram representation</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Analyse all house of commons speeches since 1970"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "[Part 1: Get a list of MPs and their affiliations](MP_speeches-Part1.ipynb)\n",
    "\n",
    "[Part 2: Download all speeches belonging to MPs in list](MP_speeches-Part2.ipynb)\n",
    "\n",
    "## Part 3: Train bigram and trigram models and use them on all speeches\n",
    "\n",
    "[Part 4: Train an LDA topic model and process all speeches with it](MP_speeches-Part4.ipynb)\n",
    "\n",
    "[Part 5: Analyse the results of the LDA model](MP_speeches-Part5.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Bigrams (Trigrams) are any two (three) words that often go together.\n",
    "For example, Maastricht treaty (House of Commons) would be converted to maastricht_treaty (house_of_commons) with such a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Load the list of MPs from Part 1\n",
    "mps = pd.read_hdf(\"list_of_mps.h5\", \"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import Phrases\n",
    "from gensim.models.word2vec import LineSentence\n",
    "import codecs\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### We use SpaCy to tokenize and POS tag each speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    # Load english language model from spacy\n",
    "    import spacy\n",
    "    nlp = spacy.load(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Directory to store Phrase models\n",
    "from config import INTERMEDIATE_DIRECTORY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Load all the speeches and metadata into a pandas dataframe and save into an hdf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "### Uncomment these bash commands to copy all speeches into one csv file.\n",
    "### This is essential if you want to run the next cell for the first time!\n",
    "\n",
    "#!echo \"body,date,debate_title,mp_constituency,mp_id,mp_name,mp_party,section_id,speech_id,speech_url,subsection_id,time\" > ./speeches/speeches.csv\n",
    "#!tail -n +2 -q mp-* >> speeches.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 5.48 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### Change False to True to compute. This may take a while!\n",
    "if False:\n",
    "    import pandas as pd\n",
    "    # Did you run the command above first?\n",
    "    try:\n",
    "        speeches = pd.read_csv(\"./speeches/speeches.csv\")\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(\"speeches.csv not found. Did you run the bash commands in the cell above?\")\n",
    "    \n",
    "    # Strip honorifics from names\n",
    "    import re\n",
    "    honorifics = r'(Mr|Mrs|Ms|Miss|Advocate|Ambassador|Baron|Baroness|Brigadier|Canon|Captain|Chancellor|Chief|Col|Comdr|Commodore|Councillor|Count|Countess|Dame|Dr|Duke of|Earl|Earl of|Father|General|Group Captain|H R H the Duchess of|H R H the Duke of|H R H The Princess|HE Mr|HE Senora|HE The French Ambassador M|His Highness|His Hon|His Hon Judge|Hon|Hon Ambassador|Hon Dr|Hon Lady|Hon Mrs|HRH|HRH Sultan Shah|HRH The|HRH The Prince|HRH The Princess|HSH Princess|HSH The Prince|Judge|King|Lady|Lord|Lord and Lady|Lord Justice|Lt Cdr|Lt Col|Madam|Madame|Maj|Maj Gen|Major|Marchesa|Marchese|Marchioness|Marchioness of|Marquess|Marquess of|Marquis|Marquise|Master|Mr and Mrs|Mr and The Hon Mrs|President|Prince|Princess|Princessin|Prof|Prof Emeritus|Prof Dame|Professor|Queen|Rabbi|Representative|Rev Canon|Rev Dr|Rev Mgr|Rev Preb|Reverend|Reverend Father|Right Rev|Rt Hon|Rt Hon Baroness|Rt Hon Lord|Rt Hon Sir|Rt Hon The Earl|Rt Hon Viscount|Senator|Sir|Sister|Sultan|The Baroness|The Countess|The Countess of|The Dowager Marchioness of|The Duchess|The Duchess of|The Duke of|The Earl of|The Hon|The Hon Mr|The Hon Mrs|The Hon Ms|The Hon Sir|The Lady|The Lord|The Marchioness of|The Princess|The Reverend|The Rt Hon|The Rt Hon Lord|The Rt Hon Sir|The Rt Hon The Lord|The Rt Hon the Viscount|The Rt Hon Viscount|The Venerable|The Very Rev Dr|Very Reverend|Viscondessa|Viscount|Viscount and Viscountess|Viscountess|W Baron|W/Cdr)'\n",
    "    h = re.compile(honorifics.replace(\"|\", r\" \\b|\\b\"))\n",
    "    speeches[\"mp_name\"] = speeches[\"mp_name\"].str.replace(h, \"\")\n",
    "    speeches[\"body\"] = speeches[\"body\"].fillna(\"\")\n",
    "    # Concatenate all speeches by a particular MP in a particular debate into one\n",
    "    speeches = speeches.groupby(['section_id', 'mp_name', \"mp_id\", 'debate_title', 'date']).apply(lambda x: \" \".join(x.body)).reset_index()\n",
    "    speeches = speeches.rename(columns={0:\"body\"})\n",
    "    \n",
    "    # Split into different parts of the hdf file because HDF seems to struggle with huge data frames\n",
    "    speeches[:len(speeches) // 2].to_hdf(\"raw_speeches.h5\", \"speeches_0\", mode=\"w\")\n",
    "    speeches[len(speeches) // 2:].to_hdf(\"raw_speeches.h5\", \"speeches_1\", mode=\"a\")\n",
    "    # Remove from memory because it may be too big and unnecessary\n",
    "    del speeches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Save speeches alone to a text file to speed up processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Save speeches to txt file first\n",
    "speeches_filepath = os.path.join(INTERMEDIATE_DIRECTORY, \"speeches.txt\")\n",
    "# Set to True if you want to run this again\n",
    "if False:\n",
    "    with codecs.open(speeches_filepath, \"w\", encoding=\"utf_8\") as f:\n",
    "        for speech in speeches[\"body\"]:\n",
    "            f.write(speech + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Create a bunch of helper functions to help us read speeches from the file, remove punctuation and whitespace and lemmatize words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting helper_functions.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile helper_functions.py\n",
    "\n",
    "def punct_space(token):\n",
    "    \"\"\"\n",
    "    helper function to eliminate tokens\n",
    "    that are pure punctuation or whitespace\n",
    "    \"\"\"\n",
    "    \n",
    "    return token.is_punct or token.is_space\n",
    "\n",
    "def line_speech(filename):\n",
    "    \"\"\"\n",
    "    generator function to read in speeches from the file\n",
    "    and un-escape the original line breaks in the text\n",
    "    \"\"\"\n",
    "    \n",
    "    with codecs.open(filename, encoding='utf_8') as f:\n",
    "        for speech in f:\n",
    "            yield speech.replace('\\\\n', '\\n')\n",
    "\n",
    "def lemmatized_sentence_corpus(filename):\n",
    "    \"\"\"\n",
    "    generator function to use spaCy to parse speeches,\n",
    "    lemmatize the text, and yield sentences\n",
    "    \"\"\"\n",
    "    \n",
    "    for parsed_speech in nlp.pipe(line_speech(filename),\n",
    "                                  batch_size=10000, n_threads=4):\n",
    "        \n",
    "        for sent in parsed_speech.sents:\n",
    "            yield u' '.join([token.lemma_ for token in sent\n",
    "                             if not punct_space(token)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Lemmatize all words in speeches and store them in text file to save memory\n",
    "Lemmatization is the process of stripping word endings to convert words to their stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 17.2 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# this is a bit time consuming - make the if statement True\n",
    "# if you want to execute data prep yourself.\n",
    "unigram_sentences_filepath = os.path.join(INTERMEDIATE_DIRECTORY, 'unigram_sentences_all.txt')\n",
    "if False:\n",
    "    with codecs.open(unigram_sentences_filepath, 'w', encoding='utf_8') as f:\n",
    "        for sentence in lemmatized_sentence_corpus(speeches_filepath):\n",
    "            f.write(sentence + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-PRON- just nip to the gentlemanâsâ\r\n",
      "to ask the secretary of state for foreign and commonwealth affairs what recent discussion -PRON- have have with the danish government about the forthcoming referendum on the maastricht treaty\r\n",
      "-PRON- know that whenever mean testing be put in place there be a cost because of the bureaucracy that be need to administer -PRON-\r\n",
      "do -PRON- right hon\r\n",
      "friend have any idea how much this particular method of mean testing will cost\r\n",
      "the hon gentleman be entirely correct\r\n",
      "-PRON- be particularly unfortunate that some of those who have be discuss at great length quite minor issue in the bill consider that -PRON- contain some serious issue that -PRON- could have be discuss say that -PRON- opposition to the original fur farming legislation be because -PRON- be a private member 's bill when -PRON- should have be a government bill\r\n",
      "now -PRON- be a government bill and although -PRON- can not undertake to give the hon\r\n",
      "gentleman full detail tomorrow -PRON- can confirm that -PRON- will be a government act and that -PRON- will go on the statute book\r\n",
      "-PRON- be happy to pass that request on to the secretary of state and -PRON- think that the whole house will congratulate the people and the civic leader of crawley on that achievement and -PRON- work over the decade in build a thriving and successful community\r\n"
     ]
    }
   ],
   "source": [
    "!tail intermediate/unigram_sentences_all.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Learn bigrams in speeches and save model to disk\n",
    "Bigrams are any two words that often go together. For example, Maastricht treaty would be converted to maastricht_treaty with such a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.61 s, sys: 208 ms, total: 3.82 s\n",
      "Wall time: 3.84 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# this is a bit time consuming - make the if statement True\n",
    "# if you want to execute modeling yourself.\n",
    "bigram_model_filepath = os.path.join(INTERMEDIATE_DIRECTORY, 'bigram_model_all')\n",
    "if False:\n",
    "    # Open unigram sentences as a stream\n",
    "    unigram_sentences = LineSentence(unigram_sentences_filepath)\n",
    "    bigram_model = Phrases(unigram_sentences)\n",
    "    bigram_model.save(bigram_model_filepath)\n",
    "else:\n",
    "    # load the finished model from disk\n",
    "    bigram_model = Phrases.load(bigram_model_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Identify bigrams in the speeches and save in txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 17.6 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# this is a bit time consuming - make the if statement True\n",
    "# if you want to execute data prep yourself.\n",
    "bigram_sentences_filepath = os.path.join(INTERMEDIATE_DIRECTORY, 'bigram_sentences_all.txt')\n",
    "if False:\n",
    "    with codecs.open(bigram_sentences_filepath, 'w', encoding='utf_8') as f: \n",
    "        for unigram_sentence in unigram_sentences:\n",
    "            bigram_sentence = u' '.join(bigram_model[unigram_sentence])\n",
    "            f.write(bigram_sentence + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-PRON- just nip to the gentlemanâsâ\r\n",
      "to ask the secretary of state for foreign and commonwealth_affairs what recent_discussion -PRON- have have with the danish government about the forthcoming referendum on the maastricht_treaty\r\n",
      "-PRON- know that whenever mean_testing be put in place there be a cost because of the bureaucracy that be need to administer -PRON-\r\n",
      "do -PRON- right hon\r\n",
      "friend have any idea how much this particular method of mean_testing will cost\r\n",
      "the hon gentleman be entirely correct\r\n",
      "-PRON- be particularly unfortunate that some of those who have be discuss at great length quite minor issue in the bill consider that -PRON- contain some serious issue that -PRON- could have be discuss say that -PRON- opposition to the original fur_farming legislation be because -PRON- be a private member 's bill when -PRON- should have be a government bill\r\n",
      "now -PRON- be a government bill and although -PRON- can not undertake to give the hon\r\n",
      "gentleman full detail tomorrow -PRON- can confirm that -PRON- will be a government act and that -PRON- will go on the statute_book\r\n",
      "-PRON- be happy to pass that request on to the secretary of state and -PRON- think that the whole house will congratulate the people and the civic leader of crawley on that achievement and -PRON- work over the decade in build a thriving and successful community\r\n"
     ]
    }
   ],
   "source": [
    "!tail intermediate/bigram_sentences_all.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Learn trigrams in speeches and save model to disk\n",
    "Trigrams are any three words that often go together. For example, House of Commons would be converted to house_of_commons with such a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.04 s, sys: 180 ms, total: 4.22 s\n",
      "Wall time: 4.22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Learn a trigram model from bigrammed speeches\n",
    "\n",
    "# this is a bit time consuming - make the if statement True\n",
    "# if you want to execute modeling yourself.\n",
    "trigram_model_filepath = os.path.join(INTERMEDIATE_DIRECTORY, 'trigram_model_all')\n",
    "if False:\n",
    "    # Open bigram sentences as a stream\n",
    "    bigram_sentences = LineSentence(bigram_sentences_filepath)\n",
    "    trigram_model = Phrases(bigram_sentences)\n",
    "    trigram_model.save(trigram_model_filepath)\n",
    "else:\n",
    "    # load the finished model from disk\n",
    "    trigram_model = Phrases.load(trigram_model_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Identify trigrams in the speeches and save in txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 20.3 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Save speeches as trigrams in txt file\n",
    "\n",
    "# this is a bit time consuming - make the if statement True\n",
    "# if you want to execute data prep yourself.\n",
    "trigram_sentences_filepath = os.path.join(INTERMEDIATE_DIRECTORY, 'trigram_sentences_all.txt')\n",
    "if False:\n",
    "    with codecs.open(trigram_sentences_filepath, 'w', encoding='utf_8') as f:\n",
    "        for bigram_sentence in bigram_sentences:\n",
    "            trigram_sentence = u' '.join(trigram_model[bigram_sentence])\n",
    "            f.write(trigram_sentence + '\\n')\n",
    "# Open trigrams file as stream\n",
    "trigram_sentences = LineSentence(trigram_sentences_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-PRON- just nip to the gentlemanâsâ\r\n",
      "to ask the secretary of state for foreign and commonwealth_affairs what_recent_discussion -PRON- have have with the danish government about the forthcoming referendum on the maastricht_treaty\r\n",
      "-PRON- know that whenever mean_testing be put in place there be a cost because of the bureaucracy that be need to administer -PRON-\r\n",
      "do -PRON- right hon\r\n",
      "friend have any idea how much this particular method of mean_testing will cost\r\n",
      "the hon gentleman be entirely correct\r\n",
      "-PRON- be particularly unfortunate that some of those who have be discuss at great length quite minor issue in the bill consider that -PRON- contain some serious issue that -PRON- could have be discuss say that -PRON- opposition to the original fur_farming legislation be because -PRON- be a private member 's bill when -PRON- should have be a government bill\r\n",
      "now -PRON- be a government bill and although -PRON- can not undertake to give the hon\r\n",
      "gentleman full detail tomorrow -PRON- can confirm that -PRON- will be a government act and that -PRON- will go on the statute_book\r\n",
      "-PRON- be happy to pass that request on to the secretary of state and -PRON- think that the whole house will congratulate the people and the civic_leader of crawley on that achievement and -PRON- work over the decade in build a thriving and successful community\r\n"
     ]
    }
   ],
   "source": [
    "!tail intermediate/trigram_sentences_all.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Now process all speeches from plain text to unigram (lemmatized), bigram and finally trigram representation\n",
    "We previously only did this for some speeches (although this depends on how you ran this whole file). This is not super efficient so you might want to modify the next two cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def clean_text(parsed_speech):\n",
    "   # lemmatize the text, removing punctuation and whitespace\n",
    "    unigram_speech = [token.lemma_ for token in parsed_speech\n",
    "                      if not punct_space(token)]\n",
    "\n",
    "    # apply the bigram and trigram phrase models\n",
    "    bigram_speech = bigram_model[unigram_speech]\n",
    "    trigram_speech = trigram_model[bigram_speech]\n",
    "\n",
    "    # remove any remaining stopwords\n",
    "    trigram_speech = [term for term in trigram_speech\n",
    "                      if term not in spacy.en.language_data.STOP_WORDS]\n",
    "\n",
    "    # write the transformed speech as a line in the new file\n",
    "    trigram_speech = u' '.join(trigram_speech) \n",
    "    \n",
    "    return trigram_speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 16.9 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# this is a bit time consuming (takes about 2h) - make the if statement True\n",
    "# if you want to execute data prep yourself.\n",
    "trigram_speeches_filepath = os.path.join(INTERMEDIATE_DIRECTORY, 'trigram_transformed_speeches_all.txt')\n",
    "if False:\n",
    "    with codecs.open(trigram_speeches_filepath, 'w', encoding='utf_8') as f:  \n",
    "        for parsed_speech in nlp.pipe(line_speech(speeches_filepath),\n",
    "                                      batch_size=10000, n_threads=4):\n",
    "            f.write(clean_text(parsed_speech) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exactly happen dog lift -PRON- find amazing -PRON- appreciate -PRON- hon friend desperate -PRON- want consider -PRON- previous point -PRON- amendment 10 driver power stop vehicle order blind person dog -PRON- seriously mean -PRON- prepared table amendment bill aim protect blind disabled_people allow driver stop middle order dog blind disabled person dog irritate driver -PRON- seriously propose -PRON- agree thrust -PRON- hon friend 's argument -PRON- right point -PRON- perfectly_possible rational fear dog example person bite close -PRON- attack fear constitute medical_condition -PRON- perfectly_rational understandable respect -PRON- hon friend member hendon_mr._dismore hon member somerton frome_mr._heath think -PRON- possible new_clause -PRON- glimpse real meaning compassionate_conservatism\r\n",
      "root_cause problem london_centric policy country -PRON- doubt individual board represent apart_from elitist group individual represent london fact matter whatev provocation -PRON- elect north_east member hon member -PRON- london_centric clique board frankly listen -PRON- -PRON- right hon friend know connection_between gospel st._mary st. cuthbert 's church chester_le_street -PRON- fight facsimile permanent display obviously commendable -PRON- add history trail north_east gospel permanent display north_east recognise cultural historical_significance north_east development christendom country\r\n"
     ]
    }
   ],
   "source": [
    "!tail -n 2 intermediate/trigram_transformed_speeches_all.txt"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:nlp]",
   "language": "python",
   "name": "conda-env-nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": true,
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 1,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
